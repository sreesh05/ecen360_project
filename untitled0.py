# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QABZAKl02eqH4t7lB6xGkyH0gq2L6Njb
"""

# prompt: mount drive

from google.colab import drive
drive.mount('/content/drive')

#Analayze the data on the Texas state, and make THE
import pandas as pd
import numpy as np



#Start analyzing the dataset aof hurricanes
#years 2001-2024
#Tornado scales EF0-EF5
''''
EF0 – Light Damage (40 – 72 mph)
EF1 – Moderate Damage (73 – 112 mph)
EF2 – Significant damage (113 – 157 mph)
EF3 – Severe Damage (158 – 206 mph)
EF4 – Devastating Damage (207 – 260 mph)
EF5 – Incredible Damage (261 – 318 mph)
pd.set_option("display.width", 100)
# '''
data_2001 =pd.read_csv("/content/drive/MyDrive/ecen 360/StormEvents_details-ftp_v1.0_d2001_c20220425.csv")#check
data_2002 = pd.read_csv("/content/drive/MyDrive/ecen 360/StormEvents_details-ftp_v1.0_d2002_c20220425.csv")#check
data_2003 = pd.read_csv("/content/drive/MyDrive/ecen 360/StormEvents_details-ftp_v1.0_d2003_c20220425.csv")#check
data_2004 = pd.read_csv("/content/drive/MyDrive/ecen 360/StormEvents_details-ftp_v1.0_d2004_c20220425.csv")#check
data_2005 = pd.read_csv("/content/drive/MyDrive/ecen 360/StormEvents_details-ftp_v1.0_d2005_c20220425.csv")#check
data_2006 = pd.read_csv("/content/drive/MyDrive/ecen 360/StormEvents_details-ftp_v1.0_d2006_c20250122.csv")#check
data_2007= pd.read_csv("/content/drive/MyDrive/ecen 360/StormEvents_details-ftp_v1.0_d2007_c20240216.csv")
data_2008= pd.read_csv("/content/drive/MyDrive/ecen 360/StormEvents_details-ftp_v1.0_d2008_c20240620.csv")
data_2009= pd.read_csv("/content/drive/MyDrive/ecen 360/StormEvents_details-ftp_v1.0_d2009_c20231116.csv")
data_2010 = pd.read_csv("/content/drive/MyDrive/ecen 360/StormEvents_details-ftp_v1.0_d2010_c20220425.csv")
data_2011  =pd.read_csv("/content/drive/MyDrive/ecen 360/StormEvents_details-ftp_v1.0_d2011_c20230417.csv")
data_2012=pd.read_csv("/content/drive/MyDrive/ecen 360/StormEvents_details-ftp_v1.0_d2012_c20221216.csv")
data_2013=pd.read_csv("/content/drive/MyDrive/ecen 360/StormEvents_details-ftp_v1.0_d2013_c20230118.csv")
data_2014=pd.read_csv("/content/drive/MyDrive/ecen 360/StormEvents_details-ftp_v1.0_d2014_c20231116.csv")
data_2015=pd.read_csv("/content/drive/MyDrive/ecen 360/StormEvents_details-ftp_v1.0_d2015_c20240716.csv")
data_2016=pd.read_csv("/content/drive/MyDrive/ecen 360/StormEvents_details-ftp_v1.0_d2016_c20220719.csv")
data_2017=pd.read_csv("/content/drive/MyDrive/ecen 360/StormEvents_details-ftp_v1.0_d2017_c20250122.csv")
data_2018=pd.read_csv("/content/drive/MyDrive/ecen 360/StormEvents_details-ftp_v1.0_d2018_c20240716.csv")
data_2019=pd.read_csv("/content/drive/MyDrive/ecen 360/StormEvents_details-ftp_v1.0_d2019_c20240117.csv")
data_2020=pd.read_csv("/content/drive/MyDrive/ecen 360/StormEvents_details-ftp_v1.0_d2020_c20240620.csv")
data_2021=pd.read_csv("/content/drive/MyDrive/ecen 360/StormEvents_details-ftp_v1.0_d2021_c20240716.csv")
data_2022=pd.read_csv("/content/drive/MyDrive/ecen 360/StormEvents_details-ftp_v1.0_d2022_c20241121.csv")
data_2023=pd.read_csv("/content/drive/MyDrive/ecen 360/StormEvents_details-ftp_v1.0_d2023_c20250216.csv")
data_2024=pd.read_csv("/content/drive/MyDrive/ecen 360/StormEvents_details-ftp_v1.0_d2024_c20250216.csv")
#nex time

#Make a frame for each csv file
# data_2001_frame = pd.DataFrame(data_2001)
# data_2002_frame = pd.DataFrame(data_2002)
# data_2003_frame = pd.DataFrame(data_2003)
# data_2004_frame = pd.DataFrame(data_2004)
# data_2005_frame = pd.DataFrame(data_2005)
# data_2006_frame = pd.DataFrame(data_2006)
# data_2006_frame = pd.DataFrame(data_2006)

category_2024 = pd.DataFrame(columns= ['TOR_F_SCALE' , 'STATE'] )

category_2024['TOR_F_SCALE'] = (data_2024['TOR_F_SCALE']).dropna().copy()#copy to
category_2024['STATE'] = (data_2024['STATE']).dropna().copy()
# category_2001_TX = category_2001[category_2001['ST']]


category_2024_TX = category_2024[(category_2024['STATE'] =='TEXAS') & (category_2024['TOR_F_SCALE']!= 'EFU')]#filter only the state of texas

import matplotlib.pyplot as plt


state_freq = category_2024_TX['TOR_F_SCALE'].value_counts()
plt.bar( state_freq.index ,state_freq.values )
print(state_freq.index ,state_freq.values)
plt.title("Storm freq in Texas(2024)")
plt.xlabel("Category")
plt.ylabel("Freq")
plt.show()

category_2023 = pd.DataFrame(columns= ['TOR_F_SCALE' , 'STATE'])
# state_texas_tor_categries = category_2001[['STATE'] == 'TEXAS']
category_2023['TOR_F_SCALE'] = (data_2023[['TOR_F_SCALE']]).dropna().copy()

category_2023['STATE'] = (data_2023[['STATE']]).dropna().copy()
# category_2001_TX = category_2001[category_2001['ST']]


category_2023_TX = category_2023[(category_2023['STATE'] =='TEXAS') & (category_2023['TOR_F_SCALE']!='EFU')]

import matplotlib.pyplot as plt


state_freq = category_2023_TX['TOR_F_SCALE'].value_counts()
plt.bar( state_freq.index ,state_freq.values )
print(state_freq.index ,state_freq.values)
plt.title("Storm freq in Texas(2023)")
plt.xlabel("Category")
plt.ylabel("Freq")
plt.show()

category_2022 = pd.DataFrame(columns= ['TOR_F_SCALE' , 'STATE'])
# state_texas_tor_categries = category_2001[['STATE'] == 'TEXAS']
category_2022['TOR_F_SCALE'] = (data_2022[['TOR_F_SCALE']]).dropna().copy()

category_2022['STATE'] = (data_2022[['STATE']]).dropna().copy()
# category_2001_TX = category_2001[category_2001['ST']]


category_2022_TX = category_2022[(category_2022['STATE'] =='TEXAS') & (category_2022['TOR_F_SCALE']!='EFU')]

import matplotlib.pyplot as plt


state_freq = category_2022_TX['TOR_F_SCALE'].value_counts()
plt.bar( state_freq.index ,state_freq.values )
plt.title("Storm freq in Texas(2022)")
plt.xlabel("Category")
plt.ylabel("Freq")
plt.show()

category_2021 = pd.DataFrame(columns= ['TOR_F_SCALE' , 'STATE'])
# state_texas_tor_categries = category_2001[['STATE'] == 'TEXAS']
category_2021['TOR_F_SCALE'] = (data_2021[['TOR_F_SCALE']]).dropna().copy()

category_2021['STATE'] = (data_2021[['STATE']]).dropna().copy()
# category_2001_TX = category_2001[category_2001['ST']]


category_2021_TX = category_2021[(category_2021['STATE'] =='TEXAS') & (category_2021['TOR_F_SCALE']!='EFU')]

import matplotlib.pyplot as plt


state_freq = category_2021_TX['TOR_F_SCALE'].value_counts()
plt.bar( state_freq.index ,state_freq.values )
print(state_freq.index ,state_freq.values)
plt.title("Storm freq in Texas 2021")
plt.xlabel("Category")
plt.ylabel("Freq")
plt.show()

category_2020 = pd.DataFrame(columns= ['TOR_F_SCALE' , 'STATE'])
# state_texas_tor_categries = category_2001[['STATE'] == 'TEXAS']
category_2020['TOR_F_SCALE'] = (data_2020[['TOR_F_SCALE']]).dropna().copy()

category_2020['STATE'] = (data_2020[['STATE']]).dropna().copy()
# category_2001_TX = category_2001[category_2001['ST']]


category_2020_TX = category_2020[(category_2020['STATE'] =='TEXAS') & (category_2020['TOR_F_SCALE']!='EFU')]

import matplotlib.pyplot as plt


state_freq = category_2020_TX['TOR_F_SCALE'].value_counts()
plt.bar( state_freq.index ,state_freq.values )
print(state_freq.index ,state_freq.values)
plt.title("Storm freq in Texas 2020")
plt.xlabel("Category")
plt.ylabel("Freq")
plt.show()

category_2019 = pd.DataFrame(columns= ['TOR_F_SCALE' , 'STATE'])
# state_texas_tor_categries = category_2001[['STATE'] == 'TEXAS']
category_2019['TOR_F_SCALE'] = (data_2019[['TOR_F_SCALE']]).dropna().copy()

category_2019['STATE'] = (data_2019[['STATE']]).dropna().copy()
# category_2001_TX = category_2001[category_2001['ST']]


category_2019_TX = category_2019[(category_2019['STATE'] =='TEXAS') & (category_2019['TOR_F_SCALE']!='EFU')]

import matplotlib.pyplot as plt


state_freq = category_2019_TX['TOR_F_SCALE'].value_counts()
plt.bar( state_freq.index ,state_freq.values )
print(state_freq.index ,state_freq.values)
plt.title("Storm freq in Texas 2019")
plt.xlabel("Category")
plt.ylabel("Freq")
plt.show()

category_2018 = pd.DataFrame(columns= ['TOR_F_SCALE' , 'STATE'])
# state_texas_tor_categries = category_2001[['STATE'] == 'TEXAS']
category_2018['TOR_F_SCALE'] = (data_2018[['TOR_F_SCALE']]).dropna().copy()

category_2018['STATE'] = (data_2018[['STATE']]).dropna().copy()
# category_2001_TX = category_2001[category_2001['ST']]


category_2018_TX = category_2018[(category_2018['STATE'] =='TEXAS') & (category_2018['TOR_F_SCALE']!='EFU')]

import matplotlib.pyplot as plt


state_freq = category_2018_TX['TOR_F_SCALE'].value_counts()
plt.bar( state_freq.index ,state_freq.values )
print(state_freq.index ,state_freq.values)
plt.title("Storm freq in Texas 2018")
plt.xlabel("Category")
plt.ylabel("Freq")
plt.show()

category_2017 = pd.DataFrame(columns= ['TOR_F_SCALE' , 'STATE'])

# state_texas_tor_categries = category_2001[['STATE'] == 'TEXAS']
category_2017['TOR_F_SCALE'] = (data_2017[['TOR_F_SCALE']]).dropna().copy()

category_2017['STATE'] = (data_2017[['STATE']]).dropna().copy()
# category_2001_TX = category_2001[category_2001['ST']]


category_2017_TX = category_2017[(category_2017['STATE'] =='TEXAS') & (category_2017['TOR_F_SCALE']!='EFU')]

import matplotlib.pyplot as plt


state_freq = category_2017_TX['TOR_F_SCALE'].value_counts()
plt.bar( state_freq.index ,state_freq.values )
print(state_freq.index ,state_freq.values)
plt.title("Storm freq in Texas 2017")
plt.xlabel("Category")
plt.ylabel("Freq")
plt.show()

category_2016 = pd.DataFrame(columns= ['TOR_F_SCALE' , 'STATE'])
# state_texas_tor_categries = category_2001[['STATE'] == 'TEXAS']
category_2016['TOR_F_SCALE'] = (data_2016[['TOR_F_SCALE']]).dropna().copy()

category_2016['STATE'] = (data_2016[['STATE']]).dropna().copy()
# category_2001_TX = category_2001[category_2001['ST']]


category_2016_TX = category_2016[(category_2016['STATE'] =='TEXAS') & (category_2016['TOR_F_SCALE']!='EFU')]

import matplotlib.pyplot as plt


state_freq = category_2016_TX['TOR_F_SCALE'].value_counts()
plt.bar( state_freq.index ,state_freq.values )
print(state_freq.index ,state_freq.values)
plt.title("Storm freq in Texas 2016")
plt.xlabel("Category")
plt.ylabel("Freq")
plt.show()

category_2015 = pd.DataFrame(columns= ['TOR_F_SCALE' , 'STATE'])
# state_texas_tor_categries = category_2001[['STATE'] == 'TEXAS']
category_2015['TOR_F_SCALE'] = (data_2015[['TOR_F_SCALE']]).dropna().copy()

category_2015['STATE'] = (data_2015[['STATE']]).dropna().copy()
# category_2001_TX = category_2001[category_2001['ST']]


category_2015_TX = category_2015[(category_2015['STATE'] =='TEXAS') & (category_2015['TOR_F_SCALE']!='EFU')]

import matplotlib.pyplot as plt


state_freq = category_2015_TX['TOR_F_SCALE'].value_counts()
plt.bar( state_freq.index ,state_freq.values )
print(state_freq.index ,state_freq.values)
plt.title("Storm freq in Texas 2015")
plt.xlabel("Category")
plt.ylabel("Freq")
plt.show()

category_2014 = pd.DataFrame(columns= ['TOR_F_SCALE' , 'STATE'])
# state_texas_tor_categries = category_2001[['STATE'] == 'TEXAS']
category_2014['TOR_F_SCALE'] = (data_2014[['TOR_F_SCALE']]).dropna().copy()

category_2014['STATE'] = (data_2014[['STATE']]).dropna().copy()
# category_2001_TX = category_2001[category_2001['ST']]


category_2014_TX = category_2014[(category_2014['STATE'] =='TEXAS') & (category_2014['TOR_F_SCALE']!='EFU')]

import matplotlib.pyplot as plt


state_freq = category_2014_TX['TOR_F_SCALE'].value_counts()

print(state_freq.index ,state_freq.values)
plt.bar( state_freq.index ,state_freq.values )
plt.title("Storm freq in Texas 2014")
plt.xlabel("Category")
plt.ylabel("Freq")
plt.show()

category_2013 = pd.DataFrame(columns= ['TOR_F_SCALE' , 'STATE'])
# state_texas_tor_categries = category_2001[['STATE'] == 'TEXAS']
category_2013['TOR_F_SCALE'] = (data_2013[['TOR_F_SCALE']]).dropna().copy()

category_2013['STATE'] = (data_2013[['STATE']]).dropna().copy()
# category_2001_TX = category_2001[category_2001['ST']]


category_2013_TX = category_2013[(category_2013['STATE'] =='TEXAS') & (category_2013['TOR_F_SCALE']!='EFU')]

state_freq = category_2013_TX['TOR_F_SCALE'].value_counts()

print(state_freq.index ,state_freq.values)
plt.bar( state_freq.index ,state_freq.values )
plt.title("Storm freq in Texas 2013")
plt.xlabel("Category")
plt.ylabel("Freq")
plt.show()

category_2012 = pd.DataFrame(columns= ['TOR_F_SCALE' , 'STATE'])
# state_texas_tor_categries = category_2001[['STATE'] == 'TEXAS']
category_2012['TOR_F_SCALE'] = (data_2012[['TOR_F_SCALE']]).dropna().copy()

category_2012['STATE'] = (data_2012[['STATE']]).dropna().copy()
# category_2001_TX = category_2001[category_2001['ST']]


category_2012_TX = category_2012[(category_2012['STATE'] =='TEXAS') & (category_2012['TOR_F_SCALE']!='EFU')]

state_freq = category_2012_TX['TOR_F_SCALE'].value_counts()

print(state_freq.index ,state_freq.values)
plt.bar( state_freq.index ,state_freq.values )
plt.title("Storm freq in Texas 2012")
plt.xlabel("Category")
plt.ylabel("Freq")
plt.show()

category_2011 = pd.DataFrame(columns= ['TOR_F_SCALE' , 'STATE'])
# state_texas_tor_categries = category_2001[['STATE'] == 'TEXAS']
category_2011['TOR_F_SCALE'] = (data_2011[['TOR_F_SCALE']]).dropna().copy()

category_2011['STATE'] = (data_2011[['STATE']]).dropna().copy()
# category_2001_TX = category_2001[category_2001['ST']]


category_2011_TX = category_2011[(category_2011['STATE'] =='TEXAS') & (category_2011['TOR_F_SCALE']!='EFU')]

state_freq = category_2011_TX['TOR_F_SCALE'].value_counts()

print(state_freq.index ,state_freq.values)
plt.bar( state_freq.index ,state_freq.values )
plt.title("Storm freq in Texas 2011")
plt.xlabel("Category")
plt.ylabel("Freq")
plt.show()

category_2010= pd.DataFrame(columns= ['TOR_F_SCALE' , 'STATE'])
# state_texas_tor_categries = category_2001[['STATE'] == 'TEXAS']
category_2010['TOR_F_SCALE'] = (data_2010[['TOR_F_SCALE']]).dropna().copy()

category_2010['STATE'] = (data_2010[['STATE']]).dropna().copy()
# category_2001_TX = category_2001[category_2001['ST']]


category_2010_TX = category_2010[(category_2010['STATE'] =='TEXAS') & (category_2010['TOR_F_SCALE']!='EFU')]

state_freq = category_2010_TX['TOR_F_SCALE'].value_counts()

print(state_freq.index ,state_freq.values)
plt.bar( state_freq.index ,state_freq.values )
plt.title("Storm freq in Texas 2010")
plt.xlabel("Category")
plt.ylabel("Freq")
plt.show()

category_2009 = pd.DataFrame(columns= ['TOR_F_SCALE' , 'STATE'])
# state_texas_tor_categries = category_2001[['STATE'] == 'TEXAS']
category_2009['TOR_F_SCALE'] = (data_2009[['TOR_F_SCALE']]).dropna().copy()

category_2009['STATE'] = (data_2009[['STATE']]).dropna().copy()
# category_2001_TX = category_2001[category_2001['ST']]


category_2009_TX = category_2009[(category_2009['STATE'] =='TEXAS') & (category_2009['TOR_F_SCALE']!='EFU')]

state_freq = category_2009_TX['TOR_F_SCALE'].value_counts()

print(state_freq.index ,state_freq.values)
plt.bar( state_freq.index ,state_freq.values )
plt.title("Storm freq in Texas 2009")
plt.xlabel("Category")
plt.ylabel("Freq")
plt.show()

category_2008 = pd.DataFrame(columns= ['TOR_F_SCALE' , 'STATE'])
# state_texas_tor_categries = category_2001[['STATE'] == 'TEXAS']
category_2008['TOR_F_SCALE'] = (data_2008[['TOR_F_SCALE']]).dropna().copy()

category_2008['STATE'] = (data_2008[['STATE']]).dropna().copy()
# category_2001_TX = category_2001[category_2001['ST']]


category_2008_TX = category_2008[(category_2008['STATE'] =='TEXAS') & (category_2008['TOR_F_SCALE']!='EFU')]

state_freq = category_2008_TX['TOR_F_SCALE'].value_counts()

print(state_freq.index ,state_freq.values)
plt.bar( state_freq.index ,state_freq.values )
plt.title("Storm freq in Texas 2008")
plt.xlabel("Category")
plt.ylabel("Freq")
plt.show()

category_2007 = pd.DataFrame(columns= ['TOR_F_SCALE' , 'STATE'])
# state_texas_tor_categries = category_2001[['STATE'] == 'TEXAS']
category_2007['TOR_F_SCALE'] = (data_2007[['TOR_F_SCALE']]).dropna().copy()

category_2007['STATE'] = (data_2007[['STATE']]).dropna().copy()
# category_2001_TX = category_2001[category_2001['ST']]


category_2007_TX = category_2007[(category_2007['STATE'] =='TEXAS') & (category_2007['TOR_F_SCALE']!='EFU')]

state_freq = category_2007_TX['TOR_F_SCALE'].value_counts()

print(state_freq.index ,state_freq.values)
plt.bar( state_freq.index ,state_freq.values )
plt.title("Storm freq in Texas 2007")
plt.xlabel("Category")
plt.ylabel("Freq")
plt.show()

category_2006 = pd.DataFrame(columns= ['TOR_F_SCALE' , 'STATE'])
# state_texas_tor_categries = category_2001[['STATE'] == 'TEXAS']
category_2006['TOR_F_SCALE'] = (data_2006[['TOR_F_SCALE']]).dropna().copy()

category_2006['STATE'] = (data_2006[['STATE']]).dropna().copy()
# category_2001_TX = category_2001[category_2001['ST']]


category_2006_TX = category_2006[(category_2006['STATE'] =='TEXAS') & (category_2006['TOR_F_SCALE']!='EFU')]

state_freq = category_2006_TX['TOR_F_SCALE'].value_counts()

print(state_freq.index ,state_freq.values)
plt.bar( state_freq.index ,state_freq.values )
plt.title("Storm freq in Texas 2006")
plt.xlabel("Category")
plt.ylabel("Freq")
plt.show()

category_2005 = pd.DataFrame(columns= ['TOR_F_SCALE' , 'STATE'])
# state_texas_tor_categries = category_2001[['STATE'] == 'TEXAS']
category_2005['TOR_F_SCALE'] = (data_2005[['TOR_F_SCALE']]).dropna().copy()

category_2005['STATE'] = (data_2005[['STATE']]).dropna().copy()
# category_2001_TX = category_2001[category_2001['ST']]


category_2005_TX = category_2005[(category_2005['STATE'] =='TEXAS') & (category_2005['TOR_F_SCALE']!='EFU')]

state_freq = category_2005_TX['TOR_F_SCALE'].value_counts()

print(state_freq.index ,state_freq.values)
plt.bar( state_freq.index ,state_freq.values )
plt.title("Storm freq in Texas 2005")
plt.xlabel("Category")
plt.ylabel("Freq")
plt.show()

category_2004 = pd.DataFrame(columns= ['TOR_F_SCALE' , 'STATE'])
# state_texas_tor_categries = category_2001[['STATE'] == 'TEXAS']
category_2004['TOR_F_SCALE'] = (data_2004[['TOR_F_SCALE']]).dropna().copy()

category_2004['STATE'] = (data_2004[['STATE']]).dropna().copy()
# category_2001_TX = category_2001[category_2001['ST']]


category_2004_TX = category_2004[(category_2004['STATE'] =='TEXAS') & (category_2004['TOR_F_SCALE']!='EFU')]

state_freq = category_2004_TX['TOR_F_SCALE'].value_counts()

print(state_freq.index ,state_freq.values)
plt.bar( state_freq.index ,state_freq.values )
plt.title("Storm freq in Texas 2004")
plt.xlabel("Category")
plt.ylabel("Freq")
plt.show()

category_2003 = pd.DataFrame(columns= ['TOR_F_SCALE' , 'STATE'])
# state_texas_tor_categries = category_2001[['STATE'] == 'TEXAS']
category_2003['TOR_F_SCALE'] = (data_2003[['TOR_F_SCALE']]).dropna().copy()

category_2003['STATE'] = (data_2003[['STATE']]).dropna().copy()
# category_2001_TX = category_2001[category_2001['ST']]


category_2003_TX = category_2003[(category_2003['STATE'] =='TEXAS') & (category_2003['TOR_F_SCALE']!='EFU')]

state_freq = category_2003_TX['TOR_F_SCALE'].value_counts()

print(state_freq.index ,state_freq.values)
plt.bar( state_freq.index ,state_freq.values )
plt.title("Storm freq in Texas 2003")
plt.xlabel("Category")
plt.ylabel("Freq")
plt.show()

category_2002 = pd.DataFrame(columns= ['TOR_F_SCALE' , 'STATE'])
# state_texas_tor_categries = category_2001[['STATE'] == 'TEXAS']
category_2002['TOR_F_SCALE'] = (data_2002[['TOR_F_SCALE']]).dropna().copy()

category_2002['STATE'] = (data_2002[['STATE']]).dropna().copy()
# category_2001_TX = category_2001[category_2001['ST']]


category_2002_TX = category_2002[(category_2002['STATE'] =='TEXAS') & (category_2002['TOR_F_SCALE']!='EFU')]

state_freq = category_2002_TX['TOR_F_SCALE'].value_counts()

print(state_freq.index ,state_freq.values)
plt.bar( state_freq.index ,state_freq.values )
plt.title("Storm freq in Texas 2002")
plt.xlabel("Category")
plt.ylabel("Freq")
plt.show()

#combine all the data into a frame

"""Jase's Part"""

from google.colab import drive
drive.mount('/content/drive')

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

#Injuries/fatalities #Jase
#Begin and End Long and Lat #Jase

df = pd.read_csv('StormEvents_details-ftp_v1.0_d2024_c20250216.csv.gz')

fatalities_texas = df[(df['DEATHS_DIRECT'] > 0) & (df['STATE'] == 'TEXAS')]

fatalities_texas = fatalities_texas[['EVENT_ID', 'DEATHS_DIRECT']]

fatalities_texas

fatalities_direct_texas = df[(df['DEATHS_DIRECT'] > 0) & (df['STATE'] == 'TEXAS')][['EVENT_ID', 'DEATHS_DIRECT']].rename_axis("Texas Fatalities in 2024")

fatalities_direct_texas

fatalities_indirect_texas = df[(df['DEATHS_INDIRECT'] > 0) & (df['STATE'] == 'TEXAS')][['EVENT_ID', 'DEATHS_INDIRECT']].rename_axis("Texas Fatalities Indirect in 2024")

fatalities_indirect_texas

injuries_direct_texas = df[(df['INJURIES_DIRECT'] > 0) & (df['STATE'] == 'TEXAS')][['EVENT_ID', 'INJURIES_DIRECT']].rename_axis("Texas Injuries Direct in 2024")

injuries_direct_texas

injuries_indirect_texas = df[(df['INJURIES_INDIRECT'] > 0) & (df['STATE'] == 'TEXAS')][['EVENT_ID', 'INJURIES_INDIRECT']].rename_axis("Texas Injuries Indirect in 2024")

injuries_indirect_texas

df_texas = df[df['STATE'] == 'TEXAS']

injuries_indirect_texas = df_texas[df_texas['INJURIES_INDIRECT'] > 0]['INJURIES_INDIRECT'].sum()
injuries_direct_texas = df_texas[df_texas['INJURIES_DIRECT'] > 0]['INJURIES_DIRECT'].sum()
fatalities_direct_texas = df_texas[df_texas['DEATHS_DIRECT'] > 0]['DEATHS_DIRECT'].sum()
fatalities_indirect_texas = df_texas[df_texas['DEATHS_INDIRECT'] > 0]['DEATHS_INDIRECT'].sum()

data = [injuries_indirect_texas, injuries_direct_texas, fatalities_direct_texas, fatalities_indirect_texas]

labels = ['Indirect Injuries', 'Direct Injuries', 'Direct Fatalities', 'Indirect Fatalities']

fig, ax = plt.subplots()
ax.pie(data, labels=labels, autopct='%1.1f%%')
ax.set_title('Harmful Storms in Texas 2024')
plt.show()



import matplotlib.pyplot as plt

data = [injuries_indirect_texas, injuries_direct_texas, fatalities_direct_texas, fatalities_indirect_texas]

labels = ['Indirect Injuries', 'Direct Injuries', 'Direct Fatalities', 'Indirect Fatalities']


colors = ['#00a9ff', '#ff8a00', '#2bda5c', '#cc0000']


fig, ax = plt.subplots()
ax.bar(labels, data, color=colors)

ax.set_title('Harmful Storms in Texas 2024')

ax.set_xlabel('Category')
ax.set_ylabel('Count')

plt.show()

import folium
import pandas as pd

df = pd.read_csv('StormEvents_details-ftp_v1.0_d2024_c20250216.csv.gz')

texas_storms = df[df['STATE'] == 'TEXAS']

texas_storms = texas_storms.dropna(subset=['BEGIN_LAT', 'BEGIN_LON', 'END_LAT', 'END_LON'])

m = folium.Map(location=[31.9686, -99.9018], zoom_start=6)

for index, row in texas_storms.iterrows():
    start_lat = row['BEGIN_LAT']
    start_lon = row['BEGIN_LON']
    end_lat = row['END_LAT']
    end_lon = row['END_LON']

    #folium.Marker([start_lat, start_lon], popup=f"Start: {row['EVENT_ID']}").add_to(m)
    #folium.Marker([end_lat, end_lon], popup=f"End: {row['EVENT_ID']}").add_to(m)

    folium.PolyLine(
        locations=[[start_lat, start_lon], [end_lat, end_lon]],
        color='blue', weight=2, opacity=0.6
    ).add_to(m)

m.save('texas_storms_map.html')

m

"""Model"""

import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error

from sklearn.metrics import accuracy_score
from sklearn.ensemble import RandomForestClassifier

#construct the model
#feed in the model data

full_frame = pd.DataFrame(

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

# Generate more realistic weather data for 100 entries
np.random.seed(42)

# Create some realistic relationships between features
temperature = np.random.uniform(15, 35, 100)
wind_speed = np.random.uniform(10, 100, 100)
humidity = np.random.uniform(40, 100, 100)
pressure = np.random.uniform(980, 1020, 100)

# Introduce relationships with storm impact (the higher the wind speed, the more severe the storm)
storm_impact = np.zeros(100)
storm_impact[(wind_speed > 80) & (pressure < 1000)] = 2  # High impact if wind speed > 80 km/h and low pressure
storm_impact[(wind_speed > 50) & (pressure < 1010)] = 1  # Medium impact if wind speed > 50 km/h and moderate pressure



# Create a DataFrame
data = {
    'Temperature': temperature,
    'Wind Speed': wind_speed,
    'Humidity': humidity,
    'Pressure': pressure,
    'Storm Impact': storm_impact
}

df = pd.DataFrame(data)


# Features (independent variables)
X = df[['Temperature', 'Wind Speed', 'Humidity', 'Pressure']]

# Target variable (dependent variable)
y = df['Storm Impact']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.7, random_state=42)

# Train a Random Forest Classifier
clf = RandomForestClassifier(random_state=42)
clf.fit(X_train, y_train)

# Predict the storm impact on the test set
y_pred = clf.predict(X_test)

# Calculate the accuracy
accuracy = accuracy_score(y_test, y_pred)

# Print the accuracy
print(f"Accuracy: {accuracy * 100:.2f}%")

# Print out the predicted values vs actual values
results = pd.DataFrame({
    'Predicted': y_pred,
    'Actual': y_test
})

print("\nPredicted vs Actual values:")
results.head(40) # Display first few rows of predicted vs actual